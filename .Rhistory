mtcars
?mtcars
mtCor
mtCor <- list(cyl=round(cor(mtcars$mpg,mtcars$cyl),3))
mtCor <- c(mtCor, list(disp=round(cor(mtcars$mpg,mtcars$disp),3)))
mtCor <- c(mtCor, list(hp=round(cor(mtcars$mpg,mtcars$hp),3)))
mtCor <- c(mtCor, list(wt=round(cor(mtcars$mpg,mtcars$wt),3)))
mtCor <- c(mtCor, list(am=round(cor(mtcars$mpg,mtcars$am),3)))
mtCor
table(mtCor)
regressor <- c("cyl","disp","hp","wt","am")
correlate <- c(round(cor(mtcars$mpg,mtcars$cyl),3),
round(cor(mtcars$mpg,mtcars$disp),3),
round(cor(mtcars$mpg,mtcars$hp),3),
round(cor(mtcars$mpg,mtcars$wt),3),
round(cor(mtcars$mpg,mtcars$am),3)
)
mtCor <- data.frame(regressor, correlate)
table(mtCor)
mtCor
regressor <- c("cyl","disp","hp","wt","am", "gear")
correlate <- c(round(cor(mtcars$mpg,mtcars$cyl),3),
round(cor(mtcars$mpg,mtcars$disp),3),
round(cor(mtcars$mpg,mtcars$hp),3),
round(cor(mtcars$mpg,mtcars$wt),3),
round(cor(mtcars$mpg,mtcars$am),3),
round(cor(mtcars$mpg,mtcars$gear),3)
)
mtCor <- data.frame(regressor, correlate)
mtCor
cor(mtcars$disp,mtcars$wt)
regressor <- c("cyl","disp","hp","wt","am", "gear","carb")
correlate <- c(round(cor(mtcars$mpg,mtcars$cyl),3),
round(cor(mtcars$mpg,mtcars$disp),3),
round(cor(mtcars$mpg,mtcars$hp),3),
round(cor(mtcars$mpg,mtcars$wt),3),
round(cor(mtcars$mpg,mtcars$am),3),
round(cor(mtcars$mpg,mtcars$gear),3),
round(cor(mtcars$mpg,mtcars$carb),3)
)
mtCor <- data.frame(regressor, correlate)
mtCor
t(mtCor)
t(mtCor[,2])
q()
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
plot(w ~ x)
barplot(w ~ x)
?barplot
barplot(w)
y <- c(1,2,3,4)
barplot(c(w,y)
)
w <- c(2, 1, 3, 1)
rm(w,x,y)
require(grDevices)
tN <- table(Ni <- stats::rpois(100, lambda = 5))
tN
r <- barplot(tN, col = rainbow(20))
lines(r, tN, type = "h", col = "red", lwd = 2)
barplot(tN, space = 1.5, axisnames = FALSE,
sub = "barplot(..., space= 1.5, axisnames = FALSE)")
barplot(VADeaths, plot = FALSE)
barplot(VADeaths, plot = FALSE, beside = TRUE)
mp <- barplot(VADeaths) # default
data("VADeaths")
VADeaths
barplot(VADeaths, beside = T) # default
q()
install.packages("kernlab")
library(kernlab)
data("spam")
spam$your
density(spam$your)
plot(density(spam$your))
prediction <- ifelse(spam$your > 0.5, "spam", "nonspam")
precition
predition
prediction
table(prediction, spam$type)
table(prediction)
table(spam$type)
set.seed(333)
smallSpam <- spam[sample(dim(spam)[1],size=10),]
spamLabel <- (smallSpam$type=="spam")*1 + 1
spamLabel
rule1 <- function(x){
prediction <- rep(NA,length(x))
prediction[x > 2.7] <- "spam"
prediction[x < 2.40] <- "nonspam"
prediction[(x >= 2.40 & x <= 2.45)] <- "spam"
prediction[(x > 2.45 & x <= 2.70)] <- "nonspam"
return(prediction)
}
rule1(smallSpam$capitalAve)
table(rule1(smallSpam$capitalAve))
table(smallSpam$type)
?table
rule1 <- function(x){
prediction <- rep(NA,length(x))
prediction[x > 2.7] <- "spam"
prediction[x < 2.40] <- "nonspam"
prediction[(x >= 2.40 & x <= 2.45)] <- "spam"
prediction[(x > 2.45 & x <= 2.70)] <- "nonspam"
return(prediction)
}
table(rule2(smallSpam$capitalAve))
rule2 <- function(x){
prediction <- rep(NA,length(x))
prediction[x > 2.8] <- "spam"
prediction[x <= 2.8] <- "nonspam"
return(prediction)
}
table(rule2(smallSpam$capitalAve))
table(smallSpam$type)
table(rule2(smallSpam$capitalAve),smallSpam$type)
q()
install.packages("caret")
q()
install.packages("ISLR")
library(caret)
library(ISLR)
data("Wage")
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list = F)
inTrain
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
featurePlot(x=training[,c("age","education","jobclass")])
featurePlot(x=training[,c("age","education","jobclass")], y=training$wage, plot = "pairs")
qplot(age,wage,data = training)
qplot(age,wage,colour=jobclass,data = training)
qq <- qplot(age,wage,colour=jobclass,data = training)
qq + geom_smooth(method = "lm", formula=y~x)
library(Hmisc)
cutWage <- cut2(training$wage,g=3)
table(cutWage)
qplot(cutWage, age, data = training, fill=cutWage, geom = "boxplot")
p1 <- qplot(cutWage, age, data = training, fill=cutWage, geom = "boxplot")
p2 <- qplot(cutWage, age, data = training, fill=cutWage, geom = "jitter")
grid.arrange(p1,p2,ncol=2)
library(ggplot2)
grid.arrange(p1,p2,ncol=2)
require("gridExtra")
grid.arrange(p1,p2,ncol=2)
cutWage2 <- cut2(training$wage,g=3)
table(cutWage)
table(cutWage2)
qplot(cutWage, age, data = training)
qplot(cutWage, age, data = training, geom = "scatterplot")
?qplot
qplot(cutWage, age, data = training, geom = "jitter")
qplot(cutWage, age, data = training, colour = jobclass)
qplot(cutWage, age, data = training, geom = "boxplot", colour = jobclass)
qplot(cutWage, age, data = training, geom = "histogram", colour = jobclass)
qplot(cutWage, age, data = training, geom = "hist", colour = jobclass)
p1
inTrain
View(Wage)
Wage$race
table(Wage$race)
density(Wage$race)
density(table(Wage$race))
qplot(Wage$race, table(Wage$race))
q()
q()
library(caret)
library(kernlab)
data("spam")
inTrain <- createDataPartition(y=spam, p=0.75, list = F)
inTrain <- createDataPartition(y=spam$type, p=0.75, list = F)
taining <- spam[inTrain,]
taining
M <- abs(cor(taining[,-58]))
M
diag(M) <- 0
M
M[34,32]
M[32,34]
which(M > 0.8, arr.ind = T)
M$num415
M[34,32]
M[32,34]
spam[,34]
spam[,32]
which(M > 0.8, arr.ind = T)
names(spam)[c(32,34,40)]
spam[c(32,34,40)]
which(M > 0.8, arr.ind = T)
plot(spam[,32], spam[,34])
plot(spam[,32], spam[,40])
plot(spam[,34], spam[,40])
spam[,32]
spam[34]
spam[34,32]
which(M > 0.8, arr.ind = T)
M[34,32]
training$num415
taining$num415
q()
library(caret)
?createFolds
library(AppliedPredictiveModeling)
data("segmentationOriginal")
inTrain <- createDataPartition(segmentationOriginal$Case, p=0.7, list = F )
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modfit <- train(Case ~ ., method = "rpart", data = segmentationOriginal)
View(segmentationOriginal)
modfit <- train(Class ~ ., method = "rpart", data = segmentationOriginal)
set.seed(125)
training <- subset(segmentationOriginal, Case== "Train")
training <- subset(segmentationOriginal, Case== "Train")
data("segmentationOriginal")
training <- subset(segmentationOriginal, Case== "Train")
testing <- subset(segmentationOriginal, Case == "Testing")
testing <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
modfit <- train(Class ~ ., method = "rpart", data = segmentationOriginal)
modfit
print(modfit$finalModel)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
modfit <- train(Area ~ ., method = "rpart", data = olive)
print(modfit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
?tree
?tree
val <- predict(modfit, newdata = newdata)
val
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
pred <- predict(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = testSA)
pred <- predict(modfit, data = testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
result <- missClass(trainSA$chd, pred)
result
result <- missClass(testSA$chd, pred)
result
pred2 <- predict(modfit, data = trainSA)
result2 <- missClass(trainSA$chd, pred2)
pred <- predict(modfit, data = testSA)
result <- missClass(testSA$chd, pred)
result <- missClass(testSA$chd, pred2)
result <- missClass(testSA$chd, pred2)
result <- missClass(testSA$chd, pred1)
result <- missClass(testSA$chd, pred2)
result <- missClass(testSA$chd, pred)
result
result2
result2 <- missClass(trainSA$chd, pred)
rm(result, result2)
result <- missClass(testSA$chd, pred)
result2 <- missClass(trainSA$chd, pred)
rm(result, result2)
set.seed(13234)
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
pred <- predict(modfit, data = testSA)
result <- missClass(testSA$chd, pred)
result <- missClass(testSA$chd, pred2)
set.seed(13234)
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
pred <- predict(modfit, data = testSA, type = "response")
pred <- predict(modfit, newdata = testSA, type = "response")
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, glm=list(family=binomial))
pred <- predict(modfit, newdata = testSA, type = "response")
require(earth)
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, glm=list(family=binomial))
rm(modfit)
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, degree = 1, glm=list(family=binomial))
pred <- predict(modfit, newdata = testSA, type = "response")
install.packages("earth")
set.seed(13234)
rm (modfit)
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, degree = 1, glm=list(family=binomial))
pred <- predict(modfit, newdata = testSA, type = "response")
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, degree = 1, method = "glm", family = "binomial")
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
modfit <- train(trainSA[,c(2,3,6,7,8,9)], trainSA$chd, data = trainSA, method = "glm", family = "binomial")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.test)
vowel.test
str(vowel.test)
as.factor(vowel.test$y)
vowel.test$y <- as.factor(vowel.test$y)
str(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
?randomForest
rf1 <- randomForest(x = vowel.train[,-1], y = vowel.train[,2:10], importance = T)
rf1 <- randomForest(x = vowel.train[,-1], importance = T)
rf1
print(rf1$importance)
print(rf1)
rf1 <- randomForest(y ~ ., data = vowel.train, importance = T)
rf1
print(rf1)
print(rf1)
print(rf1$importance)
print(rf1)
rf1 <- randomForest(y ~ ., data = vowel.train, mtry = 3, importance = T, na.action = na.omit)
print(rf1)
round(importance(rf1),2)
round(importance(rf1),2)
data("segmentationOriginal")
training <- subset(segmentationOriginal, Case== "Train")
testing <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
modfit <- train(Class ~ ., method = "rpart", data = training)
modfit
modFit$finalModel
modfit$finalModel
library(pgmm)
data(olive)
olive = olive[,-1]
modfit <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
val <- predict(modfit, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modfit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
pred <- predict(modfit, newdata = testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
result <- missClass(testSA$chd, pred)
pred2 <- predict(modfit, data = trainSA)
result2 <- missClass(trainSA$chd, pred2)
q()
q()
q()
q()
q()
q()
q()
q()
pop <- 1:1000
pop
n <- sample(pop, 100)
plot(n)
plot(pop)
sd(pop)
sd(n)
mean(pop)
mean(n)
mu <- mean(pop)
sig <- sd(pop)
lb <- mu - sig
ub <- mu + sig
in <- (pop > lb & pop < ub )
tween <- (pop > lb & pop < ub )
sum(tween)
tween / pop
ls
sum(tween)
578/1000
pop[tween,]
tween
?sd
sd
sig
var(pop)
sig^2
578/1000
cent<- pop - mu
cent / sig
stand <- cent / sig
plot(stand)
q()
library(swirl)
swirl()
exit
q()
install.packages("tidyverse")
install.packages("nycflights13")
library(nycflights13)
data("flights")
str(flights)
q()
install.packages("bookdown")
install.packages("gapminder")
install.packages("Lahman")
q()
q()
vignette("xtableGallery")
install.packages(c("assertthat", "backports", "chron", "curl", "data.table", "DBI", "devtools", "digest", "dplyr", "evaluate", "forecast", "formatR", "Hmisc", "htmltools", "jsonlite", "loo", "markdown", "matrixStats", "memoise", "mvtnorm", "quantmod", "R6", "Rcpp", "RcppEigen", "readr", "RMySQL", "rsconnect", "RSQLite", "rstan", "shiny", "shinyjs", "shinystan", "sourcetools", "SparseM", "sqldf", "StanHeaders", "stringi", "survival", "swirl", "tibble", "tidyr", "tseries", "viridis", "XML", "zoo"))
q()
mean()
mean
show
predict
lm
colSums
dgamma
show
predict
lm
dgamma
colSums
mean
q()
shiny::runApp('coursera/20170703_devDataProd/project/shinyMPG')
install.packages("V8")
install.packages(""V8"")
install.packages("V8")
runApp('coursera/20170703_devDataProd/project/shinyMPG')
model2 <- lm(mpg ~ wt + cyl, data = mtcars)
model2
pred2 <- predict(model2, mtcars)
?predict
?pch
runApp('coursera/20170703_devDataProd/project/shinyMPG')
runApp('coursera/20170703_devDataProd/project/shinyMPG')
runApp('coursera/20170703_devDataProd/project/shinyMPG')
runApp('coursera/20170703_devDataProd/project/shinyMPG')
?plot
runApp('coursera/20170703_devDataProd/project/shinyMPG')
runApp('coursera/20170703_devDataProd/project/shinyMPG')
runApp('coursera/20170703_devDataProd/project/shinyMPG')
runApp('coursera/20170703_devDataProd/project/shinyMPG')
runApp('coursera/20170703_devDataProd/project/shinyMPG')
q()
setwd("~/code/r/artOfR")
library(tm)
?new
?tm
setwd("~/code/r")
txt <- system.file("texts","artOfR",package = "tm")
(art <- Corpus(DirSource(artOfR),readerControl = list(reader = readPlain, language = "la", load = TRUE)))
setwd("~/code/r/artOfR")
new("PlainTextDocument",.Data="001_start.R")
library("tm")
install.packages("NLP")
library("tm")
rm(txt)
setwd("~/code/r/artOfR")
mytxt <- new("PlainTextDocument",.Data="001_start.R")
?tm
vignette(tm)
vignette("tm")
?Corpus
setwd("~/code/r")
txt <- system.file("texts", "artOfR", package = "tm")
str(txt)
art <- VCorpus(DirSource(txt, encoding = "UTF-8"), readerControl = list(language="lat"))
art <- VCorpus(DirSource(artOfR, encoding = "UTF-8"), readerControl = list(language="lat"))
getwd()
?system.file
txt <- system.file("artOfR", package = "tm")
txt <- system.file("sqliteHlp.txt", package = "tm")
doc <- Corpus(VectorSource("sqliteHlp.txt"))
doc
print(doc)
docs <- tm_map(docs, content_transformer(tolower))
doc <- tm_map(doc, content_transformer(tolower))
doc[1]
doc[2]
inspect(doc)
inspect(doc[[1]])
inspect(doc[[2]])
inspect(doc[[1]])
lapply(doc[1], as.character)
doc <- Corpus(VectorSource(sqliteHlp.txt))
install.packages("SnowballC")
summary(doc)
?system.file
?file.path
cname <- file.path("C:\Users\Mark\Documents\code\r\", "artOfR")
cname <- file.path("C:/Users/Mark/Documents/code/r", "artOfR")
dir(cname)
docs <- VCorpus(DirSource(cname))
summary(docs)
q()
q()
q()
q()
q()
library(tm)
?TermDocumentMatrix
q()
q()
q()
q()
q()
q()
q()
q()
q()
q()
setwd("~/code/r/coursera/20170724_capstone/swiftkeyProject/splitMergeReduce")
q()
